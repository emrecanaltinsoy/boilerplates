{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow as mlf\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlf.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = client.list_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlf.start_run() as run:\n",
    "    mlf.log_param(\"my\", \"param\")\n",
    "    mlf.log_metric(\"score\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment name, which must be unique and case sensitive\n",
    "experiment_id = mlf.create_experiment(\n",
    "    \"Social NLP Experiments\",\n",
    "    artifact_location=Path.cwd().joinpath(\"mlruns\").as_uri(),\n",
    "    tags={\"version\": \"v1\", \"priority\": \"P1\"},\n",
    ")\n",
    "experiment = mlf.get_experiment(experiment_id)\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlf.set_experiment(experiment_name=\"Social NLP Experiments\")\n",
    "\n",
    "with mlf.start_run(experiment_id=experiment.experiment_id) as run:\n",
    "    mlf.log_param(\"my\", \"param\")\n",
    "    mlf.log_metric(\"score\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlf.set_experiment(experiment_name=\"Default\")\n",
    "\n",
    "with mlf.start_run(experiment_id=experiment.experiment_id) as run:\n",
    "    mlf.log_param(\"my\", \"param\")\n",
    "    mlf.log_metric(\"score\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mlflow-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bca7ebfe12f2253493a7b61f232390864b9cbfa2dee6b9736ec8b5349055e21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
